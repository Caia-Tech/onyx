{
  "training": {
    "data_glob": "./data.jsonl",
    "tokenizer_name": "NousResearch/Hermes-2-Pro-Llama-3-8B",

    "max_seq_len": 256,
    "batch_size": 4,
    "tokens_per_step": 8192,

    "num_epochs": 1,
    "learning_rate": 3e-4,
    "min_lr": 3e-5,
    "warmup_steps": 50,
    "weight_decay": 0.1,

    "_comment_1": "===== CONSERVATIVE MEMORY TUNING =====",
    "memory_reg_weight": 0.0002,

    "_comment_2": "===== MODE COLLAPSE FIXES =====",
    "label_smoothing": 0.1,
    "entropy_reg_weight": 0.01,
    "feedback_strength": 0.5,

    "_comment_3": "===== DIVERSITY MONITORING =====",
    "monitor_diversity": true,
    "monitor_memory_states": false,
    "monitor_every": 0,
    "alert_top10_mass": 0.7,
    "alert_entropy_ratio": 0.3,
    "alert_effective_vocab": 100,
    "alert_memory_norm": 100.0,

    "use_m3_optimizer": true,
    "m3_beta_slow": 0.99,
    "m3_slow_freq": 50,
    "m3_slow_weight": 0.1,

    "gradient_clip": 1.0,

    "save_dir": "./checkpoints",
    "save_every_epoch": true,
    "keep_last_n": 5,

    "log_every": 50
  },

  "architecture": {
    "d_model": 384,
    "n_layers": 6,
    "n_heads": 6,
    "n_kv_heads": 2,
    "head_dim": 64,
    "d_ff": 4096,

    "max_seq_len": 4096,
    "vocab_size": 128258,

    "rope_base": 500000.0,

    "use_hope_attention": true,
    "self_referential_keys": true,
    "self_referential_values": true,
    "generate_own_values": true,
    "use_short_conv": true,
    "conv_kernel_size": 4,
    "use_memory_gate": true,

    "memory_type": "linear",
    "use_delta_rule": true,
    "normalize_keys": true,

    "_comment_memory": "Conservative memory tuning - safer than aggressive values",
    "memory_lr_init": 0.06,
    "memory_decay_init": 0.87,
    "max_memory_lr": 0.15,
    "memory_chunk_size": 64,

    "use_cms_ffn": true,
    "cms_num_levels": 4,
    "cms_base_chunk": 32,
    "cms_chunk_multiplier": 2,
    "cms_aggregation": "learned"
  }
}
